\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{array}
\usepackage{soul}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{{Secure Privacy Preserving Deep Learning against GAN attacks}\\
\author{\IEEEauthorblockN{Aseem Prashar}
\IEEEauthorblockA{\textit{EECS department} \\
\textit{Wichita State University}\\
Wichita, USA \\
prasharaseem@gmail.com}
\and
\IEEEauthorblockN{Sergio Salinas}
\IEEEauthorblockA{\textit{EECS department} \\
\textit{Wichita State University}\\
Wichita, USA \\
sergio.salinasmonroy@wichita.edu}
}
}
\maketitle

\begin{abstract} 
Deep learning is a class of machine learning algorithms that use a cascade of multiple layers of nonlinear processing units for feature
extraction and transformation. Each successive layer uses the output from the previous layer as input. Artificial neural network based
deep learning is becoming increasingly popular in classification fields. Deep learning benefits from larger input data sets and can be
revolutionary to organizations that have access to sizable raw data. In
the recent years,  researchers have proposed decentralized collaborative learning architectures that allow multiple participants
multiple participants to share their data to train deep learning models. However, privacy and confidentiality concerns limit the
application of this approach, preventing certain organizations such as medical institutions to fully benefit from collaborative deep
learning. 
%Generative adversarial networks (GANs) consists of two neural
%networks, pitted against one another. They are adept at mimicking any distribution of data and are used widely in image, video and
%voice generation. There has been a recent interest in utilizing the mimicking properties of GANs to fashion attacks on privacy
%preserving deep learning systems. In this attack, GANs are leveraged to generate prototypical samples of the targeted training set that
%was meant to be private. Since the attacks are designed to exploit intrinsic weaknesses in privacy preserving deep learning models,
%they are effective even when differential privacy and obfuscation techniques are employed.
In this paper, we propose a collaborative deep learning approach that allows an organization to collaborate with other entities
to improve its deep-learning model while preserving its privacy. 
%enables a main benefactor to render himself immune to the threats
%posed by a GAN
%based attack. 
Specifically, our proposed system protects the organization's privacy by ...
\end{abstract}

\begin{IEEEkeywords}
Neural Network, Deep learning, GANs
\end{IEEEkeywords}

%---------------------------------------------------------------------------------
\section{Introduction}
%---------------------------------------------------------------------------------
In the past few decades, deep learning has generated a lot of interest in the research and academic community due to its great ability
to automatically classify large amounts of data. This has led to breakthroughs in many fields ranging
from autonomous driving, and natural language processing to genetic research \cite{}.
%It is no surprise that deep learning has seen a significant investment by technology giants such as Google, IBM and Facebook. 
This revolutionary technology is especially fruitful for large corporations that need to automatically process very large data sets
to provide deep learning inference services to their users. For example, Facebook collects data from their users to train deep learning
models that help them to \hl{[Add what services facebook offers with these data]} \cite{}.
% This can simultaneously yield effective models with wide applications as well as raise pertinent privacy concerns.

%Please add a few citations about how deep neural networks are being used in those areas. You can add news articles with the 
% following bibtex sytax:
%@misc{label, 
%author= {},
%title={},
%year={},
%howpublished={url to news article}
%}

Although it is possible to collect large-scale data to train deep learning models in some application domains, e.g., online social
networks, there are other fields where such centralized data collection is currently infeasible due to privacy
concerns.
In particular, users' data can contain various types of private information that needs to be kept secret from third-parties such as the
companies that centrally collect data to provide deep learning services. These data
can include
%It is only inevitable that a
%subset of the sample space contains sensitive information that was accidentally captured without user consent.  Other privacy concerns
%regarding data ownership have also been raised since the trained model is generally a 
intellectual property (IP), 
%. Other %red flags are centered around 
medical data protected by Health Insurance and Portability and Accountability Act (HIPA), and student records protected by the Family
Educational Rights and Privacy Act (FERPA) \cite{act1996health,blechner2002health}. 
%While medical
% community
%By sharing their data, organization can receive improved deep learning inference. However, 
%stands to benefit from deep learning, 
%the privacy concerns around these type of data male it impossible to share with an untrusted third-party such as a deep learning
%service provider. 
%medical history of patients makes collecting of data samples a challenging task. 

Instead of sharing private data with a third-party, users could locally train their own deep learning models using their own
data. However, since a single user only has access to a small data set compared to the data set that could be centrally
collected by the third-party, its locally trained deep learning model can suffer from over generalization, which significantly
degrades its ability to provide correct inferences. 
%Moreover, over generalization of models trained on single source of training dataset can have significant
%effect on the model's usability. 
For instance, a hospital trained a deep neural network using to recognize patients with pneumonia based on their
chest X-ray images using its own records. Although this neural network was successful classifying records from patients that were
treated in the hospital, its performance significantly dropped when tested with images from other patient treated at a different
hospital \cite{zech2018variable}. 
%This indicates that models trained on single source datasets can produce confounding results. 
Moreover, many organizations may not have large enough local data sets to train a deep learning model with satisfactory
accuracy. 
%Accessibility of training datasets in hospital that do not have sufficient resources or samples currently is also a concern.
 
The above outlined issues beg for a deep learning solution that can achieve high accuracy while preserving privacy. 
Researchers have made some headway in this direction by leveraging distributed learning. 
\cite{shokri2015privacy}.
In this approach, a set of distributed users locally
train a deep learning model only using their own data. To overcome the challenge of over generalization and small
data sets, they send certain parameters of their model to a central server, who aggregates them. 
Then, the users can download the aggregated parameters to improve their local models. This approach achieves high accuracy.
Although   users do not send their data to the central server, recent studies have shown that it is possible for users of the
distributed learning server to recreate samples of other users using a generative adversarial network (GAN) even when the victim users 
obfuscated their private data before training \cite{hitaj2017deep}.

In this paper we propose, implement, and analyze a distributed deep learning framework that enables a user to benefit from 
high accuracy distributed learning while preserving its privacy and the privacy of all other users. 
Specifically, our framework operates as follows. First, all users train a local deep learning model using only their local data.
Second, the framework randomly selects a set of users to upload their parameters to the server, who aggregates them. The main user
never uploads its parameters. Third, the main user and the selected users download the aggregated parameters and update their local
deep learning models. The iteration continues with until the main user's deep learning model achieves a minimum
accuracy, or a maximum number of iterations is reached.

The main contribution of our approach is that it allows the main user to leverage the data sets form the other users to train a local
deep learning model with high accuracy while protecting its private data from the parameter server, and other users who
may launch sophisticated GAN based attacks as described in \cite{hitaj2017deep}. The proposed architecture is independent of the
underlying neural network structure and is therefore, highly adaptable.

% We accomplish this by a two pronged approach.
% First, we randomly select users that can upload and download parameters from the server at each iteration. This prevents the
% attacks in \cite{hitaj2017deep} by limiting the repeated and predictable exposure of potential victims to the malicious users.
% Second, we enable a user with insufficient but extremely sensitive sample set to benefit from the architecture, while completely
% safeguarding itself from GAN based attacks. 

To verify the efficacy of our approach, we implement it using a deep convolutional neural network (CNN), and the scripting language
LUAJIT. We run our experimental simulation on an  M4 instance on the Amazon Web Service's Elastic Compute Cloud (AWS EC2).  The train
the CNN to classify images from the MNIST dataset which is the standard for image classification.
We observe that our approach can achieve up to 95.18\%  accuracy for the main user when there are 20 other users in the
system with each one having 50\% probability of being selected to upload their parameters at each iteration. 
%In comparison, the accuracy when all participants were selected, was 95.17\% with other comparable variables. 
This is a comparable accuracy to the one that can be achieved by running a non-privacy-preserving centralized apporach, i.e.,  98.17\%.
%The privacy violating centralized architecture with comparable variables yields an accuracy of 98.17\%. 
%We achieve these results without deploying any additional computationally intensive obfuscation or cryptographic techniques. 
We also measure the tradeoff between privacy and accuracy, and show that the main user can easily choose the most appropriate
trade-off by tuning the selection probability of the other users. 


%---------------------------------------------------------------------------------
\section{Related Work}
%---------------------------------------------------------------------------------

Deep neural networks have outperformed traditional machine learning approaches for many tasks, and are the tool of choice in many
fields. Specifically, Deep learning has been successfully used for facial recognition \cite{krizhevsky2012imagenet}, image classification, 
\cite{simard2003best}, and speech recognition \cite{hinton2012deep, graves2013speech }, where it is expected to achieve better
performance than humans in the near future. However, directly applying these techniques to fields that deal with private data is
challenging. The reason is that they need to centrally collect data at a third-party that organizations may not trust
\cite{chicurel2000databasing}. This is particularly challenging in medical and financial applications where the privacy of the users is
governed by federal legislation and needs to be kept private. 

% This has however raised some privacy issues.

To protect users' data privacy, some researchers have proposed to use secure multiparty computations (SMC) 
\cite{vaidya2003leveraging,7040943} SMC is ... \hl{[Provide one or two sentences about what is SMC]} 
%In , the authors survey multi party computation as well as other techniques. They also evaluate SMC's effectiveness and
%cost in context of secure data processing.
Sheikh et al. \cite{sheikh2010distributed} propose a SMC that divides and distributes private data blocks among participants and can
prevent the participants from learning the data from  each other. This approach assumes a semi-honest threat model,
where a malicious  participant attempts to learn the private from other users but does not deviate from the proposed
protocol. 
%datahonest parties are incapable of discovering private data of other parties. This technique is however contingent
%on the malicious
%parties being semi-honest parties.
Miyajima et al. \cite{miyajima2016new} propose a back propagation learning method for secure data computation and learning on a cloud
based system using SMC. %solve security risks associated with cloud computing using SMC. 
Bonawitz et al. \cite{bonawitz2017practical}  proposed an SMC protocol to aggregate mobile user data that maintains its efficacy 
even if there are some users who dropout of the system. 
Unfortunately, SMC is computationally expensive for the users participating in the system, which can be impractical for mobile users
an IoT devices. Moreover, SMC reveals the result of the computation to all parties, which may be a privacy risk for certain
applications. 

%d
%To overcome constraints in a mobile user setting, some researchers haveby leveraging SMC
%. They focus their work on creating a robust protocol 

Some researchers have proposed differential privacy to guarantee data privacy protection in distributed deep learning. In 
Abadi et al. \cite{abadi2016deep} propose a novel differential privacy algorithm to training deep neural networks with a modest
accuracy cost and a feasible computational complexity. They provide theoretical analysis of the the privacy cost, complexity and
training efficiency of their proposed approach. 
%neural networks where users employ
%differential privacy to hide their information. They Their work however does not account for distributive collaborative deep learning.
%jthe added noise will scale with size
%of the participants. Ultimately, the amount of noise added will render the shared data to have no
%practical use.
Song et al. \cite{song2013stochastic} investigate effects of differential privacy on mini batch SGD. They observe that increased batch
size ameliorates the impact of differential privacy on the variability of SGD. 
%The authors, however, also observe an upper limit to the
%batch that can be utilized to control the variability produced by the privacy preserving noise.
Chase et al. \cite{chase2017private} propose an algorithm that combines  SMC and differential privacy. 
Unfortunately, since differential privacy adds noise to the private data, the accuracy degradation increases with the number of users
in the system. Hence, differential privacy approaches suffer from poor scalability. 

To protect the privacy of the users while allowing a large amount of users to participate in training of deep learning
models, researchers have recently proposed distributed learning. Specifically, Shokri et al. \cite{shokri2015privacy} propose 
%a  system that enables collaborative training for deep neural networks in a privacy
%preserving manner. In the paper the authors design and test 
a protocol where the users locally train a deep neural network and then share a small subset of its parameters
with a server. The server aggregates the parameters, and then the users choose which parameters to download. 
Using the downloaded the parameters, the users can improve their deep learning models without having to observe the data sets from the
other users, which preserves privacy. Under this approach, the users are able to train their models to a high accuracy. 
%uploads  enables %the participants to preserve the privacy of %their dataset while drawing benefits from other participants' trained model.

Unfortunately, the privacy-preserving distributed learning proposed by Shikri et al. \cite{shokri2015privacy} is vulnerable to an
attack where users upload maliciously crafted parameters. Specifically, Hitaj  et al. \cite{hitaj2017deep} design
an attack where a malicious user 
%exploits the architectural weaknesses in distributed learning. 
%system proposed in \cite{abadi2016deep}. 
%The attack proposed in \cite{hitaj2017deep} 
leverages Generative Adversarial Networks (GAN) to replicate samples of the data sets from other users in the system, which compromises
their privacy. 
%their attack model immune to majority of obfuscation techniques. 
\hl{The authors claim that the  deceptive adversarial influence exerted by their attack model is a more potent threat than the ones
posed by techniques involving Model Inversion attacks in} \cite{deng2012mnist}.\hl{ [Is the approach by Shokri et al vulnerable to
this attack? If not, delete]. }

%---------------------------------------------------------------------------------
\section{Deep Neural Networks}
%---------------------------------------------------------------------------------
Deep neural networks are a type of machine learning that has recently shown high accuracy in data classification tasks. Traditional
machine learning requires manual feature selection, which can be time consuming and inaccurate. In contrast, deep learning
learns the most relevant features in the data on its own. In other words, the deep neural networks can be trained with raw data without
the burden of preprocessing it. Since deep neural networks have more hidden layers compared to traditional neural networks, their
accuracy is proportional to the amount of data used for training, i.e., the larger the training data set the more accurate that the
deep neural networks become. These advantages make deep neural networks a very effective technique to perform data classification
tasks. In this section, we describe the architecture of deep neural networks and their training methods. 

%The layers of deep neural networks can be of three types: input, hidden or output. 

%------------------------------------------------------------------------------
\subsection{Architecture}
%------------------------------------------------------------------------------
%the network, process it, and provides an input to the first hidden later. Hidden layers continue the data flow until they reach
%the output layer, which provides the results of the classification task to the user. 
%Deep neural networks contain two or more hidden layers. The large number of hidden layers enable deep neural networks to
%learn nonlinear relationships between the input and the output, making them powerful tools for many tasks beyond classification. 

\begin{figure}[t]
\includegraphics[width=8cm, keepaspectratio]{SimpleNN}
\caption{A neural network with $m$ inputs, $j$ outputs,  $N$  hidden layers, and $I$ neurons per layer.}
\label{fig:SimplNN}
\end{figure}
In this work, we consider multilayer perception (MLP), which is one of the most common deep neural network architectures. An
MLP is formed by multiple layers where each layer consists of many nodes. Each node takes 
as input a weighted average of the previous layer's node outputs, and the output of an special node called the bias.  
The nodes use a non-linear activation function to the compute their output. Together, the weights used in the weighted average and
the biases from the special neurons are called the parameters of the deep neural network. 

% from nodes in the
% previous layer.The layers are sequentially connected to
% each other by 
% previous one and the next layer in the architecture. The output of a node
% within a layer is a function of the weighted averages of the outputs from nodes in the previous layer. Each node also receives an
% additional input from a special neuron called the bias.  
% %The weighted average of inputs plus the bias is referred to as the total input for the
% %neuron. 

%This activation
%function is crucial in introducing non-linearity in neural networks. The non-linearity allows the modeling of complex relationships
%between the input and the outpout data. 

%a a feed-forward based network, i.e., it has no feedback loops, The MLP architecture 

Figure \ref{fig:SimplNN} shows the structure of a typical classification MLP with $m$ input nodes and $j$ outputs nodes. The neural network
has $N$ hidden layers and each layer has $I$ neurons. Intuitively, this MLP takes a data sample represented as a vector of length
$m$ on its input layer, and outputs the probability that it belongs to the $j$th category on the $j$th output neuron.

Formally, the output of the $i$th neuron at layer $k$ is defined as follows:
$$a^i_k=f(W_k a_{k-1}),$$
where $f$ is the activation function, $W_k$ is the weight matrix of layer $k$,
%which controls how input signal from previous layer,
and $a_{k-1}$ is the vector of neuron outputs from the the $k-1$th layer. 
%affects the output of the current neuron. 

There are several non-linear activation functions that can be used for function $f$, including sigmoid,
hyperbolic tangent, and rectified linear unite (ReLU) \cite{} \hl{Add a reference. The Deep learning Book should be fine}. In this
work, we will focus on the... function, which is give by\hl{[add the description and the mathematical formula for the most relevant
one]}

%function which outputs
%values between 0 and 1, normalizing the output of each neuron. Hyperbolic tangent activation function 
%is zero centered and makes it easier to model inputs that have strongly negative, neutral or positive values. 
%Rectified Linear Unit (ReLU) is an increasing popular activation function that aids in the quick convergence of the network. 

%In a network that is tasked to classify inputs to one of the $j$ fixed number of outputs, 
The output layer is usually implemented with the SoftMax activation function. The output of this function is between zero and
one, and it is used to represent the probability that the data sample observed at the input layer belongs to each of the $j$
categories. Formally, the SoftMax activation functions is defined by
%divides it by their sum, resulting in a probability
%score that
%the given input belongs to class $j$. which is given by
$$f(z_j) = \frac{e^{z_j}} {(\sum_ke^{z_k})}, \forall j$$.
where $z_j$ is ...\hl{Add description of} $z_j$, and $z_k$ is \hl{add description of} $z_k$. 


%---------------------------------------------------------------------
\subsection{Training}
%---------------------------------------------------------------------
Before a neural network can be used to perform inference, e.g., classify images, it needs to be trained to learn the highly non-linear
relationships between the inputs and the correct outputs. Training finds the 
parameters of the deep neural network, i.e., its the weights and biases, that result in the inferences with the highest accuracy.  

Although there are many training algorithms, their general workflow is the same. 
First, we randomly initialize the deep neural network parameters.
Then, we take a data sample from the training data set, e.g., an image, and feed it as input to the deep neural network. Based on the
inference error, e.g., the difference between the probability given by the neural network that the image belongs to certain category
and the correct probability, we adjust the value of the parameters in such a way that the inference error is reduced. This iteration is
repeated until the inference error converges or a maximum number of iterations is reached. 


%There are several algorithms that can tackle this non-linear optimization problem. A training dataset is a dataset of sample
%inputs which has  known outputs or labels. In supervised learning,  we feed the inputs from a training dataset to the neural network
%during its training phase and compare computed output with the corresponding labels.

The main challenge in training is finding a parameter update at each iteration that drives the deep neural network to the optimal
classification accuracy. The most common way of finding these updates is by using the gradient descent (GD) algorithm, or one of its
variants. In the rest of this subsection, we provide a brief overview of these algorithms. 

%---------------------------------------------------------------------
\subsubsection{Gradient Descent Algorithm}
%---------------------------------------------------------------------
The GD algorithm finds the parameter updates in two steps: error  forward propagation, and back propagation. 
 %calculates the parameter update at each iteration by performing forward
%propagation, and then updates the parameters through
%backward propagation. 

In the forward propagation step, the GD algorithm passes the samples in its training data set through the
deep neural network and obtains the output for each sample based on the current value of its parameters. Then, the GD computes the
error function, which measures the difference between the outputs of the neural network and the correct classification solutions,
which we call labels. There are multiple ways of calculating the error. In this work, we focus on the mean squared error function,
which is defined as follows:
\begin{align}\label{eq:errorFunction}
 E= \frac{1}{n} \sum_{n=1}^{n}(y_i -\hat{y_i}),
\end{align}
where $n$ is the the number of sample in the training dataset, $y_i$ is the output calculated by the neural network and 
$\hat{y_i}$ is the correct label for the $i$th sample.


%The error is given by the difference between the label of the training set and the computed output by the neural network. 
Next, in the back propagation step, the GD algorithm 
computes the partial derivative of the error function with respect to the
parameters of each neuron in the deep neural network, which indicate how much each parameter contributed to
the error. Based on the partial derivatives, the GD algorithm computes an update for each parameter. 
%computes the partial derivative of the error function
%with respect to each parameter using their current values. These values are called the gradients. 
The GD  obtains the new value of parameters by subtracting an scaled value of the partial derivatives, i.e.,  
%Consider E to be the error function over the entire dataset, then the new value of parameter $w_i$ is given by:
%\begin{equation*}
$$w_j = w_j -\alpha \frac{\partial E}{\partial w_j} $$
where  $\alpha$ is the learning rate. 

%The parameters in the network are then adjusted to reduce the computed gradient.
The GD algorithms continues with the forward pass, error calculation, back propagation and parameter update iteration until a minimum
error is achieved or a maximum number of iterations is reached \cite{} \hl{[Please provide a citation. Preferable NOT The deep
learning book.]}.

A key parameter in the GD algorithm is learning rate $\alpha$.   Selecting an optimal learning
rate is crucial since a smaller learning rate results in a large number of iterations needed to reach the minimum error value. This
causes longer and computationally expensive convergence time. On the other hand, if the chosen learning rate is too large the algorithm
can fail to converge and overshoot the desired minimum, leading to oscillations.  Optimal learning rates are generally chosen through
trial and error. In this work, we use the most commonly used values in the literature to implement the deep neural networks. 

%We then pass all of our data through the network and calculate the error function. Typically, the error function is the
%average of the sums of the difference between the predicted value and the given label. Formally we can define the 


%In the next part of GD algorithm we back-propagate this error. 

%\end{equation*}

%This process is iteratively repeated until the cost function converges and we minimize the error.


%we first need to set an objective function that measures the classification
%error of the neural network based on its output. 
%iteratively solves an optimization problem as follows. 
%first calculates the derivative of the objective function with respect to
% each of the current parameters. Based
%on these partial derivatives, it
%calculates a gradient that is added to the current value of the parameters. 
%updates the parameters and repeats the process iteratively to achieve more accuracy.  



%Gradient Descent (GD) is an iterative algorithm that is often used to calculate the parameters of neural
%networks, i.e., their weights and biases. At each iteration, the  algorithm updates the parameters based on the gradient of the 
%an error function evaluated with the current parameters. The iterations continue until a minimum is reached. 
%Since the objective function is non-linear, the algorithm can only guarantee that it converges to a local minimum.


% Some of the most commonly used learning rates are 0.001, 0.00  and 0.01.

%The GD algorithm works to minimize the error function by
%taking 'steps'towards the desired minimum. A learning rate, $\alpha$ is
%chosen which dictates the size of each step at every iteration. 

%---------------------------------------------------------------------------------
\subsubsection{Stochastic Gradient Descent}
%--------------------------------------------------------------------------------- 
Although the GD algorithm is effective at finding the parameters of DNNs, all  training samples in the dataset need to be processed
before a single update is made to the parameters. That is, the algorithm processes the complete training data at each iteration. 
This is computationally intensive and time consuming. 


To overcome this challenge, we can use Stochastic Gradient Descent(SGD) \cite{} \hl{[Add citation. Preferably NOT the deep learning
book]}. Unlike the GD algorithm where all samples in the training data set are used in a single iteration, SGD only uses a random 
selected subset of samples for calculating the parameter updates at each iteration. 
%SGD then uses this fraction of dataset do a forward pass, calculate error and back propagate the to find the gradients of each
% parameter. 
%This process is identical to the one outlined for GS. 
If multiple samples are chosen but the total size remains significantly smaller than the size of the complete
training dataset, then SGD algorithm is called Mini-batch Gradient Descent.


Since SGD only uses a subset of the sample in the training data set at each iteration, its computing time is
significantly smaller compared to GD.  Moreover, since SGD explores different parts of the solution space by randomly selecting samples
at each iteration, it has a higher probability of escaping local minima, and finding better solutions than the GD algorithm. 
If only one sample is chosen per iteration, then the SGD algorithm is said to achieve maximum
stochasticity. However,
the randomized selection of data samples can also cause updates made to the parameters to be less accurate. This results in an overall
meandering path to the local minima. Consequently, one can choose between speed (provided by SGD) and accuracy of each step (provided by
GD). For larger datasets SGD and Mini-Batch GD is preferred since taking more slightly inaccurate updates is preferred over a
single slower update in one epoch. For smaller, datasets GD can be sued to obtain more accurate results in fewer iterations and within
a feasible amount of time. 

%The size of the subset of samples, called mini-batch, used at each iteration has to be chosen
%carefully. A small batch can reduce the computing time at each iteration, but may increase the number of iterations needed to converge.

Formally, the SGD can is defined as follows.  Let $w$ denote the flattened vector of all weights and biases of a deep neural
network. 
%which is defined as the difference between the actual output of the objective
%function and the
%predicted output of the network. 
%Our aim is to compute the slope of the cost function and the direction we should move to update our
%parameters. 
Then the $j$th parameter of $w$ is given by:
%\begin{equation*}
\begin{align}\label{eq:SGD}
w_j = w_j -\alpha \frac{\partial E_i}{\partial w_j}, 
\end{align}
where $\alpha$ is the learning rate,  $E_i$ is the value of the error function defined in \ref{eq:errorFunction} computed over
minibatch $i$, and  $\frac{\partial E_i}{\partial w_j}$ denotes the partial derivative of $E_i$ with respect to parameter $w_j$. 
 

%---------------------------------------------------------------------------------
\section{Problem Formulation}
%---------------------------------------------------------------------------------
In this section, we describe our considered collaborative deep learning model, and the threat model. 

%---------------------------------------------------------------------------------
\subsection{System Model} \label{sec:systemModel}
%---------------------------------------------------------------------------------

In this section, we describe a deep learning system with a set of users $\mathcal{U}= \{u_0, \dots,u_N\}$, where $N$ is the total
number of
users. Each user has a collection of
private dataset  $\mathcal{D}= \{d_0, \dots,d_N\}$. 
%We assume a reference  participant, $u_0$ whose dataset $d_0$ is significantly smaller
%than datasets $d_1$ to $d_N$ belonging to users $u_o$ to $u_N$. 
Let $w_i$ be the flattened vector of parameters for the $i$th user. The
deep learning system aims to share parameters of each user $u_0$ to $u_N$  trained privately on datasets $d_0$ to $d_N$ in a privacy
preserving manner.

To do this, all participants in this system agree in advance on a
common network architecture and common learning objective. The system also includes a secure parameter server (PS), which maintains the
latest values of parameters uploaded given by $w^{(global)}$. Each user, $u_i$ in the system selects a $\theta_d^{i}$, which is the fraction of  $w^{(global)}$ parameters that the user will download from the PS. 
The user $u_i$ also choses a value $\theta_u^{i}$ which is the fraction of $w_i$ that user chooses to upload to the PS.

Each participant, $u_i$ randomly initializes its parameters $w_i$ and selects a learning rate, $\alpha$.
The participant then downloads $|\theta_d^{i} \times w_i|$ parameters from PS and overwrites its corresponding local parameters.
$u_i$ then runs the stochastic gradient descent algorithm for one epoch on its local dataset and trains its model. The local parameter vector, $w_i$ is updated according to \eqref{eq:SGD}. The SGD yields a new set of parameters, $w_i^{(new)}$.
In the next step, $u_i$ computes the parameter gradient $\Delta w_i$ which is vector of changes in all local parameters due to the SGD. This is computed by
$$\Delta w_i =  w_i^{(new)} -  w_i$$ 
The gradient  $\Delta w_i$ is indicative of how much each parameter has to change to more accurately perform regression on the local dataset $d_i$.
Consider $S$ to be a set of indices with the top  $|\theta_u^{i} \times \Delta w_i|$ values in $\Delta w_i$ 
The participant then uploads  $\Delta w_S$ values to the PS.
These uploaded values represent the parameters in the local model that have undergone the largest changes due to the SGD. 

When a participants makes a valid attempt to upload $\Delta w_S$ parameters to the PS, parameter vector of PS,  $w^{(global)}$, is updated as follows:
$$w^{(global)} =  w^{(global)} +  \Delta w_S$$

In this scenario we assume all participants, $u_0$ to $u_N$, interact with the server atomically.
That is, at any given time, only one participant can upload or download parameters from the server. This prevents over writing of parameters or race conditions from occurring within the server.

%--------------------------------------------------------------------------------------------
\section{Neural Network Architecture}
%--------------------------------------------------------------------------------------------

In this paper we use a multilayer perceptron (MLP) in a classic feed forward arrangement. Each layer in the network is fully connected to the next layer. The networks takes images as its input to its first layer. It then funnels this input through multiple hidden layers. An activation function is then applied to the output of each hidden layer. For this network we choose the Rectified Linear Unit or ReLU as the activation function. Since this network serves as a classification network, the log soft max activation function is applied to the last layer. This results in outputs that are squashed into probabilities that sum to one. 
Figure \ref{fig:ClassNN} shows the structure of a typical feed forward MLP deep neural network. The network is fed a raw image of  $m \times m$ pixels. Each pixel is an individual input which is funneled through $N$ hidden layers and ReLU activation function with $I$ neurons in each layer. The neural network produces $j$ outpputs with each putput mapping to a single class. In a classification network such as this, each output $a_1$ through $a_j$ reflects the probability of the image belonging to that class. All ouputs pass throught the softmax layer and therefore sum to 1. 

\begin{figure}[!h]
\includegraphics[width=8cm, keepaspectratio]{ClassificationNN}
\caption{Neural network depicting an image with $m \times m$ pixels fed as input, $j$ outputs  $N$  hidden layers and with $I$ neurons in layer.}
\label{fig:ClassNN}
\end{figure}
The parameter server is responsible for maintaining the current values of all parameters. Since it should be accessible to all
participants , the server can be implemented as any form of updatable cloud storage. However, for the purpose of this experiment we
chose to implement it as another neural network. 




%---------------------------------------------------------------------------------
\subsection{Threat Model}
%---------------------------------------------------------------------------------
The core prinicple motivating distributed learning is the idea that users do not wish to share their private training data. This data can be sensitive and an unverified user might attempt to maliciously violate the sharer's privacy on the pretext of model training.

We consider a malicious threat model for the parameter server and the collaborators. Specifically, the collaborators will attempt to learn private information about the reference user's dataset based on the parameters that the reference user uploads. 
In addition, one or multiple  collaborators will attempt to actively trick the reference user to reveal its private information by uploading malicious parameters. 

Instead of sharing the parameters of its deep neural, the malicious party will collect the parameters from its victim user. The malicious party will then replicate the victim's data, ultimately violating the the victim's privacy.
  
Since the threat is not dependent on the adversary compromising the
central Parameter Server, it remains viable. In effect, the adversary does not have to control the PS or the service
provider to execute his attack. The attack is more effective when adversarial influence is exercised \cite{hitaj2017deep}. This would imply that the adversary is an active participant that is adapting his gradients in real time during the current learning process.

%describe an attack that results in privacy leakage in
%collaborative deep learning system proposed in
%\cite{Shokri}.  The attack results in a malicious user inferring sensitive information from a victim's dataset. 

%Specifically, the proposed attack the goal of the  adversary is to extract information from a victim about a class of data he does
%not own. The
%adversary deceives victim into releasing more information about the specific class by presenting himself as an honest participant in
%the collaborative learning  process.    The adversary does launches the
%attack by pretending to be an honest participant and building a local GAN unbeknownst to the other participants.

%The threat model is dependent on an active insider. However, 

%\subsection{Attack Posed}

In particular the attack operates as follows. Suppose all participants including the adversary agree on general specifications such as
the type of neural network and labels on which training would take place as described in Section \ref{sec:systemModel}. Let another
participant in the collaborative deep learning
model be the victim $u_V\in\mathcal{U}$ that declares the labels $[a,b]$. The adversary $u_A\in\mathcal{U}$ declares labels $[b,c]$ implying that the
adversary has no data on class $a$. By deploying the attack, the adversary stands to gain useful information about class $a$.

The adversary then uses the private GAN to generate models that look like class $a$, which the adversary deceivingly mislabels as $c$.
This prompts the victim  $u_V$ to release more information about the class $a$ in order to distinguish between classes 
$a$ and $c$. Therefore the victim releases more data on class a now than he initially intended to.

This can be further summarized as follows:
\begin {enumerate}
\item Assuming victim $u_V$ declares labels $[a,b]$ and adversary $u_A$ declares labels $[b,c]$
\item We then run the collaborative learning protocol for several epoch and stop when we reach a specified accuracy.
\item During this process, the $u_V$ downloads a percentage of parameters from parameter Server and updates his local model.
\item $u_V$'s local model is trained on classes $a$ and $b$
\item $u_V$ uploads a section of his model to Parameter Server
\item The adversary trains is slotted to engage with the Parameter Server
\item $u_A$ downloads the percentage of parameters from the PS and updates his model
\item $u_A$ then trains his local GAN to mimic class $a$.
\item $u_A$ generates class a samples from the GAN and mislabels them intentionally as class c.
\item $u_A$ uploads a percentage of his parameters to the PS
\end {enumerate}
During the process of convergence, $u_A$ will be able to covertly exert influence on the learning process via the mislabeling of class
$a$.

In this paper, we present a collaborative learning scenario that prevents the reference user from releasing more
information about a class, and ultimately it protects the reference user's privacy. We design the interaction of the reference user
with Parameter Server such that $u_V$ is not RefU

\section{A Privacy-preserving Collaborative Learning Algorithm}

\begin{figure*}[!h]
\includegraphics[width=\textwidth, keepaspectratio]{HighLevelArch}
\caption{High level architecture of our proposed neural network.}
\label{fig:HighLevel}
\end{figure*}

This architecture works by ensuring privacy to the reference user by limiting its exposure to other collaborators. We structure this algorithm such that a primary participant, the reference user, $r_0$ benefits the most and is afforded the highest level of protection against GAN-based attacks. We envision this architecture materializing in a manner that involves the reference user compensating other collaborators for the parameters and abstract data to train its model. Since the architecture inherently obscures the absolute data, we are also able to preserves privacy for paid collaborators involved.


Specifically, we propose a system that considers a reference participant with a much smaller data set as the most significant benefactor of this architecture. We consider $u_0\in\mathcal{U}$ to be our reference user with reference dataset $d_0\in\mathcal{D}$ such that $d_0$ is much smaller than all other $d \in\mathcal{D}$


We structure the system to ensure that the privacy of the reference
user, $u_0$ is not affected by the inventive GAN based attack proposed in \cite{hitaj2017deep}. Table \ref{table:1} summarises the notations used in this
paper.

\begin{table}[!h]
\centering
\caption{Table1: Summary of notations used in the paper}
\label{table:1}
\begin{tabular}{ | m{0.12\columnwidth} | m{0.8\columnwidth}| } 
\hline
\textbf{Notation} & \textbf{Description} \\
 \hline\hline

$N$ & Number of participants excpet the system\\
\hline
$u_0$ & Reference User and the  main benefactor of the architecture \\
\hline
$M$ & Mini batch size used for stochastic gradient descent\\
\hline
$\theta_d$, $\theta_u$ & Fraction of parameters selected for download and upload from total available parameters \\
\hline
$W_k$ & Weight matrix for layer K in the neural network\\
\hline
$w$ & Flattened vector of all parameters in the neural network. \\
\hline
$\Delta w$ & Vector of changes in all local parameters due to SGD\\
\hline
$w^{(global)}$ & Flattened parameter vector for server\\
\hline
$E$ & Error Function defining the difference btween the computed value and expected value of the objective function \\
\hline
$\alpha$ & Learning rate of the stochastic gradient descent algorithm\\
\hline
$S$ & Set of $\theta_u$ largest indices selected from $w$ \\
\hline
\end{tabular}
\end{table}


 
We define the following terms, $\theta_u$
$R$
The Algorithm works as follows:
\begin {enumerate}
\item A pool of participants is created where each participant has a sizeable dataset
\item Out of the pool of participants, a random subsection of participants is selected to interact with the PS in this period. We call this period a round which is denoted by $r$.
\item In each round, $r_i$, the selected participant, $u_i$ is able to interact with the PS such that no other participant can interact with the PS at the same time.
\item During its interaction with PS, the participant will perform the following steps:
\begin {enumerate}
  \item train independantly on its local dataset for one epoch, to calculate parameter gradient, $\Delta w$ 
  \item  at the end of the epoch, $u_i$ will select the $\theta_u$ highest gradients, $\Delta w$. The $u_i$ uploads these values to the PS.
  \end {enumerate}
\item For each subsequent epoch, the participant will first download $\theta_d$ percentage of parameters from the server. The participant will then repeat the steps a and b.
\item We repeat these steps for every participant selected in the round. At the end of the round, the reference user downloads $\theta_d$ percentage of parameters from the PS.
\item The reference user then trains its model locally on its small dataset. 

\end {enumerate}
As you can see the, the reference user does not share its parameters with other users. It benefits from random particpants from the architecture but does not expose itself to any attacks. Since the participants selected from the pool each round are randomized, we ..



%-------------------------------------------------------------------------------
\section{Experimental Setup}
%-------------------------------------------------------------------------------

We evaluate the learning performance of the reference user under our proposed privacy-preserving collaborative learning algorithm. We
measure ... and compare it to a the learning performance of a traditional deep neural network without collaborative learning. 
%We wrote the source code based on the pseudocode provided in paper \cite{Shokri}. 
We implement all algorithms using Torch with the neural network packages in the scripting language LUAJIT, and run them on an M4 instance on the Amazon Web Service's Elastic Compute Cloud (AWS EC2).

For this experiment, we implement a similar neural network structure for the reference user as well as other participants. Although one can chose any neural network architecture, we use a multilayer perceptron (MLP) in a classic feed forward arrangement. 
Each neural network is designed to have 1024 inputs
corresponding to each pixel in the provided 32x 32 pixel image of a handwritten number \cite{deng2012mnist}. The output layer is a
tensor of size 10 where each output corresponds to the probability that the given input is a specific number between 0 and 9. The model
also has 2 hidden layers where an activation function is applied to the output of each hidden layer.
Initially, the input is reshaped into a 1 dimensional tensor of size 1024 and funneled to the first hidden layer. The hidden layers are constructed via \textit{nn.Linear()} via which linear transformation can be applied. It then produces a tensor of size 128 as its output. The second hidden layer accepts a tensor of size 128 as input to yield a tensor of size 64 as output. We use a non-linear activation function called Rectified Linear Unit (ReLU) which is applied after each hidden layer. The last layer of the model is a log soft max layer coded by the \textit{nn.LogSoftMax()} module.  This activation function is usually applied to the end of all classification models where it squashes the inputs into probabilities that sum to one.
The Architecture described above are represented in Figure\ref{fig:MLPArch} as printed out by Torch7

%We were able to replicate their original setup using
%Torch and nn packages in LUAJIT scripting language.  
%The tests on the proposed solution were run and hosted 


We used the MLP implementation of neural network using the function \textit{nn.Sequential} container via the Torch nn package. They are
fully connected and the neural network has input data of size 1024 (32 x 32) and feed fowards

%-------------------------------------------------------------------------------
\subsection{Datasets}
%-------------------------------------------------------------------------------
We conducted our experiments using the MNIST dataset \cite{deng2012mnist}. The MNIST dataset is a standard dataset used in image
recognition.
It contains images of hand-written grayscale digits ranging from 0 to 9. The dimension of each image is 32 X 32 pixels. There
are 60,000 such images in their training dataset and 10,000 images in their test dataset.

For this experiment, we normalize the images so that they are centered. 

We set the size of the local dataset of each participant to 1 \% of the training dataset images. 
The Reference User starts with a training set of 60 images.



%--------------------------------------------------------------------------------------------
\subsection{Hyperparameter Setup}

%--------------------------------------------------------------------------------------------
Hyperparameters are parameters that control the collaborative learning process. Unlike the actual neural-network parameters, they are usually set before the training commences and remain unchanged during the process.
They are crucial since they directly influence the behavior of training algorithm and have a large impact on the performance and accuracy o the model.
The learning rate is set at $0.1$ and weight decay is set to $1e-7$. The batch size is 10 samples and the number of participants is 20. We vary the $\theta_u$ and epochs in different scenarios. 

\begin{figure}[!h]

\centering
\includegraphics[scale = 0.2, keepaspectratio]{NNArchitecture}
\caption{MLP architecture displaying the tensor size at various stages in the neural network. }
\label{fig:MLPArch}

\end{figure}


%--------------------------------------------------------------------------------------------
%\subsection{Framework}
%---------------------------------------------------------------------------------------------

%We conduct our experiment within the Torch 7 and Torch 7 nn framework. Torch is a popular framework utilized for deep learning by major
%software companies. The code for the experiment is written in LuaJIT which is a scripting language based on Lua.  We deploy our
%architectural framework with multiple neural networks on the AWS EC-2 machine to leverage greater processing speed.

%-------------------------------------------------------------------------------
\section{Experiment Results}

%-------------------------------------------------------------------------------

\centering
\begin{figure}[!h]
\includegraphics[width=8cm, keepaspectratio]{SingleUserBaselines}
\caption{Single User with varying sample size.}
\label{fig:SingleUser}
\end{figure}

\begin{figure}[!h]
\includegraphics[width=8cm, keepaspectratio]{RandomVsAll}
\caption{Comparison between randomized interaction and complete interaction with server. }
\label{fig:RandVsAll}
\end{figure}

\begin{figure}[!h]
\includegraphics[width=8cm, keepaspectratio]{VaryingPoolofParticipants}
\caption{Accuracy of Distributed SGD for varying participants available for interaction with the PS.}
\label{fig:VaryingPoolofParticipants}
\end{figure}

\begin{figure}[!h]
\includegraphics[width=8cm, keepaspectratio]{VaryingProbabilityInteraction}
\caption{Accuracy of Distributed SGD for varying probability of interaction with the PS. }
\label{fig:VaryingProbabilityInteraction}
\end{figure}


\begin{figure}[!h]
\includegraphics[width=8cm, keepaspectratio]{VaryingThetaU}
\caption{Accuracy of Distributed SGD for different upload gradient selection rate, unevenly. }
\label{fig:VaryingThetaU}
\end{figure}

Figure \ref{fig:SingleUser} shows the accuracy for a varying number of epoch for a single user trained on different dataset sizes. The plot shows that a single user trained on a larger dataset has a higher accuracy. The user with the highest accuracy has had access to the complete MNIST training dataset of 60,000 samples. 

Figure \ref{fig:RandVsAll} shows the accuracy for varying epochs for our proposed algorithm when participant interact randomly with the server. The other plotline indicates the accuracy over varying epochs when all participants interact with the server. The plotlines show that randomized interaction over several epochs yields accuracy that is in close proximity to the one yielded by complete interaction with PS. For randomized interaction, the probability of interaction with PS for each participant per epoch was set to $0.5$.

Figure \ref{fig:VaryingPoolofParticipants} shows the accuracy of varying participant availability for varying epochs. The plots show that a higher number of participants available for randomized interaction with the PS will yield greater accuracy. The plotline with highest accuracy represented 50 participants that were available for randomized interaction with PS.

Figure \ref{fig:VaryingProbabilityInteraction} shows the accuracy for varying epochs plotted for varying probabilities of participant interaction with PS. We see that greater probability of interaction with the server results in a higher model accuracy. However, the accuracy yielded by model where all participants interact is in close proximity to accuracy yielded by models with lesser probabilities of interaction with PS. Over several epoch the lines representing randomized interaction reflect a smooth convergence.

Figure \ref{fig:VaryingThetaU} we plot the accuracy of our proposed algorithm with varying upload gradient selection rate over varying epochs. The plot shows that the percentage of uploaded parameters, $\theta_u$, is directly proportional to the resulting accuracy of the model. However, the accuracy difference between the sharing all parameters and only $ 10\% $ percent of parameters is insignificant.





\section{Conclusion}


\section{Authors and Affiliations}


\section{Identify the Headings}


\section{Figures and Tables}



\bibliographystyle{IEEEtran}
\bibliography{references}


\end{document}